# **Бинарный классификатор**

Проект реализует **нейросетевой бинарный классификатор** на PyTorch.  
Модель обучается разделять точки в диапазоне `[0,1]×[0,1]` на два класса по правилу `x + y > 1` с использованием простой, но эффективной архитектуры и мониторинга качества на тестовой выборке.

## Датасет

Датасет состоит из `500` точек с двумя признаками `x` и `y`, сгенерированных случайным образом в диапазоне `[0, 1]`.  
Каждая точка имеет метку класса:  
- `1` — если `(x + y) > 1`,  
- `0` — в противном случае.  

Таким образом, задача — **бинарная классификация** с линейно разделимой границей.  
Данные разделены на **обучающую выборку (80%)** и **тестовую выборку (20%)** для оценки качества модели на невиданных данных.

### Таблица оптимального количества точек:
| Количество точек | Ожидаемая точность | Цель использования | Описание | Когда использовать |
|------------------|---------------------|--------------------|----------|--------------------|
| **50–100**       | 85–95%              | **Быстрое тестирование кода** | Минимум данных для проверки, что модель работает, градиенты обновляются, `loss` падает. | Отладка, написание кода, эксперименты с архитектурой. |
| **100–200**      | 90–98%              | **Базовое обучение и проверка** | Достаточно для стабильного обучения. Модель учится, но может быть нестабильность на тесте из-за малого размера. | Учебные примеры, демонстрации, небольшие эксперименты. |
| **300–500**      | **100%**            | **Полное обучение с 100% точностью** | Модель видит все возможные комбинации. Идеально выучивает линейную границу. | Когда нужна идеальная точность, проверка выразительности модели. |
| **500–1000**     | **100%**            | **Обучение с запасом устойчивости** | Данные покрывают весь диапазон `[0,1]×[0,1]`. Модель устойчива к случайностям. | Подготовка к продакшену, финальные тесты. |
| **1000+**        | 95–99%              | **Реалистичные задачи / с шумом** | Много данных + шум → моделирование реального мира. | Изучение переобучения, шума, обобщения.

## Архитектура модели

Модель состоит из **трёх слоёв**:

1. **Входной** — принимает 2 признака (`x`, `y`), соответствующих 2 входным нейронам.  
2. **Скрытый** — линейное преобразование в 16 нейронов с последующей активацией **ReLU**.  
3. **Выходной** — линейное преобразование из 16 нейронов в 1 нейрон с активацией **Sigmoid**, выдающей вероятность принадлежности к классу `1`.

### Графическое отображение архитектуры:
![Архитектура модели](/assets/schema.png)

## Обучение

Обучение модели выполняется с помощью класса `Trainer`, который инкапсулирует весь процесс: подготовку данных, настройку оптимизатора, прямой и обратный проход, а также мониторинг метрик.

### Основные этапы:

1. **Подготовка данных**  
   - Датасет из 500 точек генерируется в классе `Dataset` с фиксированным `seed=42` для воспроизводимости.  
   - Данные автоматически делятся: **80% — обучающая выборка**, **20% — тестовая** (`train_test_split`).  
   - Признаки (`x`, `y`) и метки преобразуются в тензоры PyTorch.

2. **Настройка модели и оптимизации**  
   - Используется модель `BinaryClassifier` с архитектурой: `2 → 16 (ReLU) → 1 (Sigmoid)`.  
   - Функция потерь: **BCELoss** (Binary Cross-Entropy).  
   - Оптимизатор: **AdamW** с шагом обучения `lr=0.01`.

3. **Процесс обучения (метод `run`)**  
   - Обучение проходит в цикле на **100 эпох**.  
   - На каждой эпохе:  
     - Обнуление градиентов (`optimizer.zero_grad()`).  
     - Прямой проход по **обучающим данным**.  
     - Вычисление ошибки (`BCELoss`).  
     - Обратное распространение (`loss.backward()`).  
     - Обновление весов (`optimizer.step()`).  

4. **Мониторинг качества**  
   - Каждые **10 эпох** выводятся:  
     - `Train Loss` — ошибка на обучающей выборке.  
     - `Test Loss` — ошибка на тестовой выборке (не участвует в обучении).  
     - `Test MAE` — **средняя абсолютная ошибка** на тестовых данных.  
   - Оценка проводится **без градиентов** (`with torch.no_grad()`).

5. **Предсказание и сохранение**  
   - Метод `predict` позволяет получить предсказание для новых данных.  
   - Метод `save` сохраняет веса обученной модели в файл (например, `.pth`).

### Пример вывода:
```
Epoch: 10, Train Loss: 0.5315, Test Loss: 0.5274, Test MAE: 0.406
Epoch: 20, Train Loss: 0.2719, Test Loss: 0.2933, Test MAE: 0.238
Epoch: 30, Train Loss: 0.1519, Test Loss: 0.1866, Test MAE: 0.153
Epoch: 40, Train Loss: 0.1084, Test Loss: 0.1454, Test MAE: 0.119
Epoch: 50, Train Loss: 0.0865, Test Loss: 0.1238, Test MAE: 0.102
Epoch: 60, Train Loss: 0.0730, Test Loss: 0.1099, Test MAE: 0.091
Epoch: 70, Train Loss: 0.0637, Test Loss: 0.0999, Test MAE: 0.083
Epoch: 80, Train Loss: 0.0569, Test Loss: 0.0922, Test MAE: 0.077
Epoch: 90, Train Loss: 0.0517, Test Loss: 0.0860, Test MAE: 0.072
Epoch: 100, Train Loss: 0.0476, Test Loss: 0.0809, Test MAE: 0.068
```

Модель достигает **высокой точности** и успешно обобщает на невиданных данных благодаря достаточному объёму данных и простой, но выразительной архитектуре.